{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba217db-c770-4df1-b125-b49d22c39f0c",
   "metadata": {},
   "source": [
    "# Temperature-Dependent EIS Analysis Part 1: Pre-RelaxIS Processing\n",
    "\n",
    "As of February 2026, this is the most up-to-date EIS analysis and processing code that we have for the Maughan lab. This is the first installation of the analysis code where you will assign temperatures to .DTA files and identify which files you want to load into RelaxIS to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef8e70b-b6e0-468f-8d3e-25e7b85c00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from PyEIS import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.pyplot import rc\n",
    "import matplotlib.ticker as ticker\n",
    "import csv\n",
    "import glob\n",
    "import statistics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "import math\n",
    "from math import pi\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rc('text',usetex=True)\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']},size='16')\n",
    "rc('text.latex', preamble=r'\\usepackage{sfmath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352f88d-f47b-4ac7-b257-0122588130ac",
   "metadata": {},
   "source": [
    "In the cell below, you will specify:\n",
    "\n",
    "1. What type of temperature log data you have (Quincy, manual-entry Excel file, or Thermotron)\n",
    "2. Where your raw .DTA files live.\n",
    "3. The parent folder where you will copy the spectra you will fit in RelaxIS.\n",
    "4. Sample name and material name (use Latex formatting for material name)\n",
    "5. Diameter and height (as well as associated error) of your pellet in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0503f9-bdb0-4016-85e2-6c19445a4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quincy = False\n",
    "Excel = True\n",
    "Thermotron_log = False\n",
    "\n",
    "temp_data_path =  '/Users/shelbygalinat/Documents/Documents/School/Grad_School/Research/EIS/SLG_3_023_Li6PS5OCN/SLG_3_023_Li6PS5OCN_temp_tracking.xlsx'\n",
    "#if Quincy data, this is the folder in which quincy wrote all of his records. It will have a f*ckton of nested folders in it.\n",
    "#otherwise, this will be the excel file or thermotron log file path\n",
    "\n",
    "#this is the folder in which all of your .DTA files are for a given experiment\n",
    "EIS_folder_path=\"/Users/shelbygalinat/Documents/Documents/School/Grad_School/Research/EIS/SLG_3_023_Li6PS5OCN/SLG_3_023_Li6PS5OCN/SLG_3_023_Li6PS5OCN_1\"\n",
    "\n",
    "#This is the folder in which your exported data will be saved\n",
    "save_folder=\"/Users/shelbygalinat/Documents/Documents/School/Grad_School/Research/EIS/SLG_3_023_Li6PS5OCN/SLG_3_023_Li6PS5OCN/SLG_3_023_Li6PS5OCN_1/for_RelaxIS\"\n",
    "\n",
    "#INPUT DIAMETER AND HEIGHT OF PELLET HERE!\n",
    "#diameter in mm\n",
    "diameter = 6\n",
    "#pellet height in mm\n",
    "height = 1.112\n",
    "\n",
    "#samplename and materialname are included in output files, so change them as appropriate, used in generating figure titles and metadata\n",
    "samplename='SLG_3_023_Li6PS5OCN_1'\n",
    "materialname='Li$_{6}$PS$_{5}$OCN'\n",
    "\n",
    "#Errors in the thickness and height, generally no need to change this.\n",
    "#err in pellet diameter (mm)\n",
    "diameter_err=0.01\n",
    "#err in pellet height (mm)\n",
    "height_err=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdbbac",
   "metadata": {},
   "source": [
    "A gigantic function block, good luck soldier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Austin's function\n",
    "#This function reads a given EIS dataset and returns the associated datetime\n",
    "def extract_EIS_time(file_path):\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        # Read the entire file content\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Look for the lines containing the date and time using regex\n",
    "        #This reads the resulting file string for a string LABEL + tab + 2 digits / 2 digits / 4 digits\n",
    "        date_regex = re.compile(r'DATE\\tLABEL\\t(\\d{1,2}/\\d{1,2}/\\d{4})\\tDate')\n",
    "        time_regex = re.compile(r'TIME\\tLABEL\\t(\\d{1,2}:\\d{2}:\\d{2})\\tTime')\n",
    "        date = None\n",
    "        time = None\n",
    "\n",
    "        for line in lines:\n",
    "            # Check if the line matches the date pattern\n",
    "            if date_regex.search(line):\n",
    "                date = date_regex.search(line).group(1) #this takes the first string found\n",
    "                #print(date)\n",
    "            # Check if the line matches the time pattern\n",
    "            if time_regex.search(line):\n",
    "                time = time_regex.search(line).group(1)\n",
    "                #print(time)\n",
    "    #puts date and time in a single string\n",
    "    date_time_str = date+'-'+time\n",
    "    # Define the format in which the date and time are provided\n",
    "    date_time_format = '%m/%d/%Y-%H:%M:%S'\n",
    "    # Convert the string to a datetime object\n",
    "    dt_object = datetime.datetime.strptime(date_time_str, date_time_format)\n",
    "        \n",
    "    return dt_object\n",
    "\n",
    "#Austin's function\n",
    "#Generates a dictionary of filename lists, where the key is the temperature and the list is the .dta files that are from the hold at that temperature\n",
    "#Will throw an error for every empty .DTA file-- don't worry about that, just check that the first one is the first empty dta file\n",
    "#Built so that it will do this process in numerical order !!!! We will need to adjust this function when QUINCY gets EIS capabilities again\n",
    "def associate_EIS_with_temperature(EIS_folder_path, ovendata, printerrors=True):\n",
    "    # Helper function to extract number from filename\n",
    "    def extract_number(filename):\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        return int(match.group()) if match else float('inf')  # Send non-numeric to end\n",
    "\n",
    "    # Get and sort .DTA files by number\n",
    "    dta_files = sorted(\n",
    "        [f for f in os.listdir(EIS_folder_path) if f.endswith('.DTA')],\n",
    "        key=extract_number\n",
    "    )\n",
    "\n",
    "    # Dict to hold files grouped by temperature\n",
    "    temp_to_files = defaultdict(list)\n",
    "    \n",
    "    # Loop through numerically sorted files\n",
    "    for filename in dta_files:\n",
    "        file_path = os.path.join(EIS_folder_path, filename)\n",
    "        try:\n",
    "            file_time = extract_EIS_time(file_path)\n",
    "        except Exception as e:\n",
    "            if printerrors:\n",
    "                print(f\"Could not read time from {filename} because it is likely empty: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Match file time to temperature hold window\n",
    "        for _, row in ovendata.iterrows():\n",
    "            if row['start_time'] <= file_time <= row['end_time']:\n",
    "                temp_to_files[row['setpoint_C']].append(os.path.basename(file_path))\n",
    "                break\n",
    "\n",
    "    # Optional: sort dictionary by temperature\n",
    "    temp_to_files_sorted = dict(sorted(temp_to_files.items()))\n",
    "    return temp_to_files_sorted\n",
    "\n",
    "#Austin's function\n",
    "#function to generate a list of colors in hex format using start color, end color, and the target folder(directory) length\n",
    "def color_gradient(startcolor,endcolor,temperatures):\n",
    "    color_list = list(startcolor.range_to(endcolor, len(temperatures)))\n",
    "    datacolor = {}\n",
    "    for temp, color in zip(sorted(temperatures), color_list):\n",
    "        datacolor[temp] = color.hex\n",
    "    return datacolor\n",
    "\n",
    "#Austin's function\n",
    "# Define a function to format the axis multiplier\n",
    "def format_axis(value, tick_number, limit):\n",
    "    if limit >= 5e9:\n",
    "        value = value / 1e9\n",
    "    elif limit >= 5e6:\n",
    "        value = value / 1e6\n",
    "    elif limit >= 5e3:\n",
    "        value = value / 1e3\n",
    "    return '{:.0f}'.format(value)\n",
    "\n",
    "#Austin's function\n",
    "# Define a function to format the axis label unit\n",
    "def labelprefix(limit):\n",
    "    prefix = ''\n",
    "    if limit >= 5e9:\n",
    "        prefix = 'G'\n",
    "    elif limit >= 5e6:\n",
    "        prefix = 'M'\n",
    "    elif limit >= 5e3:\n",
    "        prefix = 'k'\n",
    "    return prefix\n",
    "\n",
    "#Austin's function\n",
    "def generate_normalization_constant(diameter,height):\n",
    "    area=pi*(((diameter/10)/2)**2)\n",
    "    heightcm=height/10\n",
    "    normconstant=area/heightcm\n",
    "    return normconstant\n",
    "\n",
    "#Austin's function\n",
    "def get_round_locator_spacing(limit):\n",
    "    # Choose a \"nice\" base spacing based on the axis limit\n",
    "    scaler=1\n",
    "    if limit >= 5e9:\n",
    "        scaler=1e9\n",
    "    elif limit >= 5e6:\n",
    "        scaler= 1e6\n",
    "    elif limit >= 5e3:\n",
    "        scaler=1e3\n",
    "    if limit > 5000*scaler:\n",
    "        return 1000*scaler\n",
    "    elif limit > 2000*scaler:\n",
    "        return 500*scaler\n",
    "    elif limit > 1000*scaler:\n",
    "        return 250*scaler\n",
    "    elif limit > 500*scaler:\n",
    "        return 100*scaler\n",
    "    elif limit > 200*scaler:\n",
    "        return 50*scaler\n",
    "    elif limit > 100*scaler:\n",
    "        return 20*scaler\n",
    "    elif limit > 50*scaler:\n",
    "        return 10*scaler\n",
    "    elif limit > 20*scaler:\n",
    "        return 5*scaler\n",
    "    elif limit > 10*scaler:\n",
    "        return 2*scaler\n",
    "    else:\n",
    "        return 1*scaler\n",
    "\n",
    "'''Shelby's function to convert an excel file used for manual temperature tracking to a temperature/time dataframe\n",
    "This assumes the excel file has been organized in a specific format - see Shelby's example file\n",
    "'''\n",
    "def extract_manual_excel_temp_data(file_path):\n",
    "    # Read the raw excel file with the Thermotron program info\n",
    "    raw_df = pd.read_excel(file_path,header=0,skiprows=3)\n",
    "    df = raw_df[raw_df['time (hr:min)'] != datetime.time(0, 0)].copy() #save a new dataframe with only non-zero times, since these are the ramp intervals as opposed to the hold intervals\n",
    "    df['setpoint_C']=df['IV (˚C)'] #add a column for setpoint to match Austin's previous dataframe for Quincy \n",
    "    df=df.drop(columns=['time (hr:min)','IV (˚C)','FV (˚C)']) #drop these columns since they aren't needed\n",
    "    df.dropna(how='all', axis=1, inplace=True) #drop any columns that are completely empty\n",
    "    return df\n",
    "\n",
    "\n",
    "#function below copied from Austin's old code\n",
    "#This function finds all folders labelled \"Hold\" in the quincy file sorting system and reads the metadata to find the start time, end time, and temperature\n",
    "def extract_hold_metadata(parent_path):\n",
    "    hold_data = []\n",
    "\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(parent_path):\n",
    "        # Check if this folder contains 'Hold' in its name\n",
    "        if \"Hold\" in os.path.basename(root):\n",
    "            metadata_path = os.path.join(root, 'metadata.csv')\n",
    "            if os.path.isfile(metadata_path):\n",
    "                try:\n",
    "                    # Read the metadata.csv file\n",
    "                    df = pd.read_csv(metadata_path)\n",
    "\n",
    "                    # Extract the first row\n",
    "                    row = df.iloc[0]\n",
    "                    \n",
    "                    start_time = datetime.datetime.strptime(row.iloc[0], '%d %B %Y %I:%M:%S %p')\n",
    "                    end_time = datetime.datetime.strptime(row.iloc[1], '%d %B %Y %I:%M:%S %p')\n",
    "                    setpoint = float(row.iloc[3])\n",
    "\n",
    "                    hold_data.append({\n",
    "                        'folder': root,\n",
    "                        'start_time': start_time,\n",
    "                        'end_time': end_time,\n",
    "                        'setpoint_C': setpoint\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to read {metadata_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(hold_data)\n",
    "\n",
    "#Shelby/ChatGPT's code for finding stable regions in thermotron temp log file and recording those \n",
    "def extract_thermo_temp_data(file_path):\n",
    "    variance=1.0,\n",
    "    min_points=3   # require stability for at least N timestamps\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Parse + clean\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['temperature_C'] = pd.to_numeric(df['temperature_C'])\n",
    "    df['setpoint_C'] = pd.to_numeric(df['setpoint_C'])\n",
    "\n",
    "    # Check if temperature is within tolerance. df['stable'] is a Boolean\n",
    "    df['stable'] = (\n",
    "        (df['temperature_C'] >= df['setpoint_C'] - variance) &\n",
    "        (df['temperature_C'] <= df['setpoint_C'] + variance)\n",
    "    )\n",
    "\n",
    "    # Identify contiguous regions where:\n",
    "    # 1) stability state changes OR\n",
    "    # 2) setpoint changes\n",
    "    df['block'] = (\n",
    "        (df['stable'] != df['stable'].shift()) | #compares value of stability Boolean in current row and the row before \n",
    "        (df['setpoint_C'] != df['setpoint_C'].shift()) #compares value of setpoint in current row and the row before\n",
    "    ).cumsum() #calculate a numerical index that increases with cumulative sum for the block number \n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _, block in df.groupby('block'): #iterate over the block column in the dataframe\n",
    "        if not block['stable'].iloc[0]: #don't count any blocks that are unstable\n",
    "            continue\n",
    "\n",
    "        if len(block) < min_points: #don't count any blocks that are stable for less than 3 timestamps at 30 second intervals, so 1.5 min\n",
    "            continue\n",
    "\n",
    "        results.append({ #add a dictionary for each block\n",
    "            'start_time': block['timestamp'].iloc[0], #timestamp in this row is the start time\n",
    "            'end_time': block['timestamp'].iloc[-1], #timestamp in the previous row is the end time... is this right?\n",
    "            'setpoint_C': block['setpoint_C'].iloc[0]\n",
    "        })\n",
    "        \n",
    "    result_df = pd.DataFrame(results)\n",
    "   # keep only the LAST stable block per setpoint in case there are multiple periods of stability at one setpoint\n",
    "    result_df = (\n",
    "        result_df\n",
    "        .sort_values('start_time')\n",
    "        .groupby('setpoint_C', as_index=False)\n",
    "        .tail(1) #keeps only the last block at this setpoint\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "#Shelby's function to determine which style of temperature data to import\n",
    "def extract_temp_data(file_path):\n",
    "    if Quincy:\n",
    "        df = extract_hold_metadata(file_path)\n",
    "    if Excel:\n",
    "        df = extract_manual_excel_temp_data(file_path)\n",
    "    if Thermotron_log:\n",
    "        df = extract_thermo_temp_data(file_path)\n",
    "    return df\n",
    "\n",
    "#Shelby's function to generate dataframes from all of the .DTA files and plot the Nyquists for each temperature, partially adapted from\n",
    "#truncated ausaplot in Austin's old code\n",
    "#plotall is a boolean that if true, will plot all of the temperatures in the nyquist dictionary\n",
    "#selected_temperatures is which temperatures you want to plot. It is overridden if plotall=True\n",
    "#keep_last_n: keep the last n replicates at each temperature\n",
    "#returndatasets is a Boolean that if true, will return the selected dataframes for future use\n",
    "def visualize_nyquists(files_found_dict,plotall,selected_temperatures,start_color,end_color,keep_last_n=None,returndatasets=True):\n",
    "    nyquist_dict = {} #create a dictionary to store the nyquists\n",
    "    # Iterate through the temperature keys in files_found_dict\n",
    "    for temp, file_list in files_found_dict.items():\n",
    "        for idx, filename in enumerate(file_list, start=1):\n",
    "            fullpath = os.path.join(EIS_folder_path, filename)\n",
    "            df = pd.read_csv(fullpath, skiprows=52, delimiter='\\t',encoding='latin1',header=0) # Read the file, skipping the first 52 rows to get to the header \n",
    "            df = df.drop([0]) # Drop the rows that contain the units (index 0) \n",
    "            df = df.reset_index(drop=True) # Reset the index \n",
    "            df=df.apply(pd.to_numeric, errors=\"coerce\") #change all the datatypes to floats - for some reason they were being read as strings\n",
    "            nyquist_dict[temp,idx,filename]=df #add the dataframe to the nyquist dictionary\n",
    "        \n",
    "    # Create colormap\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"gradient\", [start_color, end_color])\n",
    "    \n",
    "    #key[0] is the temperature, key[1] is the number of replicates for a specific temp\n",
    "    # Normalize the number of replicates globally (across all temperatures) for color gradient purposes, I think\n",
    "    all_keys = [key[0] for key in nyquist_dict.keys()]\n",
    "    norm = mcolors.Normalize(vmin=min(all_keys), vmax=max(all_keys))\n",
    "    \n",
    "    # Group DataFrames by key[0], which is the temperature\n",
    "    grouped_nyquist = defaultdict(list)\n",
    "    for key, df in nyquist_dict.items():\n",
    "        grouped_nyquist[key[0]].append((key, df))\n",
    "        \n",
    "    # Sort each group's dataframes by key[1], which is the replicate number \n",
    "    for group_key in grouped_nyquist:\n",
    "        grouped_nyquist[group_key].sort(key=lambda x: x[0][1])\n",
    "        \n",
    "    for temp in grouped_nyquist:\n",
    "        datasets = grouped_nyquist[temp]\n",
    "        # Apply truncation\n",
    "        if keep_last_n is not None:\n",
    "            datasets = datasets[-keep_last_n:]\n",
    "        grouped_nyquist[temp] = datasets\n",
    "    # Determine temps to plot\n",
    "    if plotall:\n",
    "        temps_to_plot = sorted(grouped_nyquist.keys())\n",
    "\n",
    "    else:\n",
    "        temps_to_plot = []\n",
    "        for temp in selected_temperatures:\n",
    "            if temp not in grouped_nyquist:\n",
    "                print(f\"Warning: Temperature {temp}°C not found in data. Skipping.\")\n",
    "            else:\n",
    "                temps_to_plot.append(temp)\n",
    "\n",
    "    if not temps_to_plot:\n",
    "        raise ValueError(\"No valid temperatures found to plot.\")\n",
    "\n",
    "    n = len(temps_to_plot)\n",
    "    cols = math.ceil(math.sqrt(n))\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    width_per_plot = 6\n",
    "    height_per_plot = 6\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * width_per_plot, rows * height_per_plot), squeeze=False)\n",
    "\n",
    "    for ax in axes.flatten()[n:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    for temp_index,(ax, temperature) in enumerate(zip(axes.flatten(), temps_to_plot)):\n",
    "        dataframes = grouped_nyquist[temperature]\n",
    "        reasonable_max_Zreals_for_plot = []\n",
    "        for i, (key, df_original) in enumerate(dataframes):\n",
    "            df=df_original.copy()\n",
    "            color = \"#ff66ff\" if i == len(dataframes) - 1 else cmap(norm(key[1]))\n",
    "            ax.plot(df['Zreal'], -df['Zimag'], linestyle='none', marker='o', color=color, markerfacecolor='white')\n",
    "            reasonable_max_Zreal_for_plot = df['Zreal'][len(df['Zreal'])-1-temp_index*5] #Shelby's jank code for getting a reasonable x limit, assuming you want to zoom in more at higher temps\n",
    "            reasonable_max_Zreals_for_plot.append(reasonable_max_Zreal_for_plot)\n",
    "        max_reasonable_max_Zreal_for_plot = max(reasonable_max_Zreals_for_plot)\n",
    "        limit = max_reasonable_max_Zreal_for_plot\n",
    "        ax.set(xlim=(0, limit), ylim=(0, limit))\n",
    "\n",
    "        prefix = labelprefix(limit)\n",
    "\n",
    "        def custom_formatter(limit):\n",
    "            def formatter(x, pos):\n",
    "                return format_axis(x, pos, limit)\n",
    "            return formatter\n",
    "\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(custom_formatter(limit)))\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(custom_formatter(limit)))\n",
    "\n",
    "        tick_spacing=get_round_locator_spacing(limit)\n",
    "        locator = ticker.MultipleLocator(tick_spacing)\n",
    "        ax.xaxis.set_major_locator(locator)\n",
    "        ax.yaxis.set_major_locator(locator)\n",
    "\n",
    "        ax.set_xlabel(rf'Z$_{{real}}$ [{prefix}$\\Omega$]')\n",
    "        ax.set_ylabel(rf'-Z$_{{imag}}$ [{prefix}$\\Omega$]')\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "        ax.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "        ax.xaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "        ax.tick_params(which='both', direction='in', right=True, top=True)\n",
    "        ax.tick_params(which='both', direction='in',length=6, right=False, top=False)\n",
    "        ax.tick_params(which='minor', direction='in',length=3, right=False, top=False)\n",
    "        ax.tick_params(width=2,which='both')\n",
    "\n",
    "    if n == 1:\n",
    "        axes.flatten()[0].set_title(rf'{materialname} {temperature} $^\\circ$C')\n",
    "    else:\n",
    "        fig.suptitle(materialname, y=0.99, x=.52)\n",
    "        for ax, temperature in zip(axes.flatten(), temps_to_plot):\n",
    "            ax.set_title(rf'{temperature} $^\\circ$C')\n",
    "    plt.tight_layout()\n",
    "    return(grouped_nyquist)\n",
    "    plt.show()\n",
    "\n",
    "#Shelby's function for copying the original .DTA files into a new directory with more useful filenames and with \n",
    "#metadata for RelaxIS appended to the start\n",
    "def copy_DTAs_with_metadata(grouped_nyquist_dict,save_folder):\n",
    "    for temp_index,(temperature) in enumerate(sorted(grouped_nyquist_dict.keys())): \n",
    "        dataframes = grouped_nyquist[temperature]\n",
    "        for i, (key, df) in enumerate(dataframes,start=1):\n",
    "            old_filename_as_DTA = key[2]\n",
    "            #old_filename_as_txt = key[2][:len(key[2])-4]+\".txt\"#save as .txt instead of .DTA, so that RelaxIS will read in the file as an unknown dataset so you can set the metadata you want\n",
    "            new_filename=str(key[0])+\"C_replicate_\"+str(i)+\"_\"+old_filename_as_DTA\n",
    "            #new_filename=str(key[0])+\"C_replicate_\"+str(i)+\"_\"+old_filename_as_txt #generate a new .txt filename that appends \n",
    "            #temp and replicate number to the first part of the original filename\n",
    "            old_filepath = os.path.join(EIS_folder_path, f\"{key[2]}\")\n",
    "            save_filepath = os.path.join(save_folder, f\"{new_filename}\")\n",
    "            new_lines = \"Temperature: \"+str(key[0])+\"C \\nReplicate: \"+str(i)+\"\\nThickness: \"+str(round(height/10,4))+\" cm\\nArea: \"+str(round(np.pi*(diameter/10/2)**2,2))+\" cm^2\\n\" #add lines to the .DTA file that include temp, replicate number, thickness (cm), and area (cm^2)\n",
    "            with open(old_filepath, \"r\", encoding=\"latin-1\") as fin, \\\n",
    "                 open(save_filepath, \"w\", encoding=\"latin-1\") as fout:\n",
    "                fout.write(new_lines) \n",
    "                for line in fin:\n",
    "                    fout.write(line) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77166431",
   "metadata": {},
   "source": [
    "Start running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874efbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate the temperature dataframe to feed into the next function\n",
    "rawovendata=extract_temp_data(temp_data_path)\n",
    "\n",
    "#make a dictionary of lists of the .DTA files. The key for each list is the temperature at which they were collected\n",
    "#each list is ordered from lowest X to highest X in EISPOT_#X \n",
    "files_found_dict=associate_EIS_with_temperature(EIS_folder_path=EIS_folder_path,ovendata=rawovendata,printerrors=False)\n",
    "\n",
    "#quickly visualize the raw Nyquists at each temperature and determine how many replicates at each temperature\n",
    "#you would like to fit in RelaxIS\n",
    "grouped_nyquist={}\n",
    "grouped_nyquist=visualize_nyquists(files_found_dict,plotall=True,selected_temperatures=[],start_color=\"#3399ff\", end_color=\"#ff66ff\",keep_last_n=3)\n",
    "\n",
    "#copy the DTA files for the selected final replicates at each temperature with additional metadata appended to the start into the save folder for fitting in RelaxIS\n",
    "copy_DTAs_with_metadata(grouped_nyquist,save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3d6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
